---
nav_title: 분석
article_title: 다변량 및 A/B 테스트 분석
page_order: 10
page_type: reference
description: "이 문서에서는 다변량 또는 A/B 캠페인의 결과를 보고 해석하는 방법에 대해 설명합니다."
---

# 다변량 및 A/B 테스트 분석

> 이 문서에서는 다변량 또는 A/B 테스트의 결과를 보는 방법에 대해 설명합니다. 아직 테스트를 설정하지 않았다면 [다변량 및 A/B 테스트 만들기를]({{site.baseurl}}/user_guide/engagement_tools/testing/multivariant_testing/create_multivariate_campaign/) 참조하세요.

캠페인이 시작된 후에는 대시보드의 **캠페인** 섹션에서 캠페인을 선택하여 각 배리언트의 성능/성과를 확인할 수 있습니다. 

## 최적화 옵션별 분석 결과

분석 보기는 초기 설정 시 [최적화를]({{site.baseurl}}/user_guide/engagement_tools/testing/multivariant_testing/optimizations/) 선택했는지 여부에 따라 달라집니다.

### 최적화 없음

캠페인 설정 시 **최적화 안 함을** 선택하면 분석 보기가 동일하게 유지됩니다. 캠페인의 **캠페인 분석** 페이지에는 대조군을 포함시킨 경우 대조군 대비 배리언트의 성능/성과가 표시됩니다.

배리언트가 여러 개 있는 이메일 캠페인에 대한 캠페인 분석의 성능/성과 섹션입니다. 표에는 수신자, 반송, 클릭 및 전환과 같은 각 배리언트에 대한 다양한 성능/성과 측정기준이 나열되어 있습니다.]({% image_buster /assets/img_archive/ab_analytics_no_optimization.png %})

자세한 내용은 메시징 채널에 대한 [캠페인 분석]({{site.baseurl}}/user_guide/analytics/reporting/campaign_analytics/) 문서를 참조하세요.

### 우승 배리언트

캠페인 설정 시 최적화를 위해 캠페인 **배리언트를** 선택한 경우, **A/B 테스트 결과라는** 캠페인 분석의 추가 탭에 액세스할 수 있습니다. 우승 배리언트가 테스트의 나머지 사용자에게 전송된 후 이 탭에는 해당 전송 결과가 표시됩니다.

**A/B 테스트 결과는** 두 개의 탭으로 나뉩니다: **초기 테스트** 및 **우승 배리언트**.

{% tabs local %}
{% tab Initial Test %}

**초기 테스트** 탭에는 타겟 세그먼트의 일부로 전송된 초기 A/B 테스트의 각 배리언트에 대한 측정기준이 표시됩니다. 모든 배리언트의 성능/성과와 테스트 중 승자가 있었는지 여부에 대한 요약을 확인할 수 있습니다.

하나의 배리언트가 95% 이상의 [신뢰도로]({{site.baseurl}}/user_guide/engagement_tools/testing/multivariant_testing/multivariate_analytics/#understanding-confidence) 다른 모든 배리언트를 능가하는 경우, Braze는 해당 배리언트에 "승자" 레이블을 표시합니다.

95% 신뢰도로 다른 모든 배리언트를 이기는 배리언트가 없고 어쨌든 가장 성능이 좋은 배리언트를 보내기로 선택한 경우에도 가장 성능이 좋은 배리언트가 발송되고 "승자"라는 레이블이 표시됩니다.

\![통계적 유의성에 대한 95% 신뢰 임계값을 충족할 만큼 충분한 확신을 가지고 다른 배리언트보다 더 나은 성능/성과를 보인 배리언트가 없는 경우 우승 배리언트를 결정하기 위해 보낸 초기 테스트 결과입니다.]({% image_buster /assets/img_archive/ab_analytics_wv_insufficient_confidence.png %})

#### 우승 배리언트 선정 방법

Braze는 [피어슨의 카이제곱 테스트를](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test) 통해 모든 배리언트를 서로 비교 테스트합니다. 이는 유의 수준 p < 0.05, 즉 95% 유의 수준에서 한 배리언트가 다른 모든 배리언트보다 통계적으로 우수한지 여부를 측정합니다. 그렇다면 우승 배리언트에는 "우승자" 라벨이 표시됩니다.

이는 0~100% 사이의 수치로 대조군과 비교한 배리언트의 성능/성과만을 설명하는 신뢰도 점수와는 별개의 테스트입니다.

배리언트는 대조군보다 더 나은 성과를 낼 수 있지만 카이제곱 테스트는 하나의 배리언트가 나머지 모든 배리언트보다 더 나은지 확인합니다. [후속 테스트를](#recommended-follow-ups) 통해 더 자세한 내용을 확인할 수 있습니다.

{% endtab %}
{% tab Winning Variant %}

**우승 배리언트** 탭에는 두 번째 전송의 결과가 표시되며, 남은 각 사용자에게 초기 테스트에서 가장 우수한 성능/성과를 보인 배리언트가 전송됩니다. **오디언스 %는** 우승 배리언트 그룹에 예약한 타겟 세그먼트의 비율에 합산됩니다.

우승 배리언트 그룹으로 전송된 우승 배리언트 결과.]({% image_buster /assets/img_archive/ab_analytics_wv_1.png %})

{% endtab %}
{% endtabs %}

A/B 테스트 전송을 포함하여 캠페인 전반에 걸쳐 우승 배리언트의 성능/성과를 확인하려면 **캠페인 분석** 페이지를 확인하세요.

### 개인화된 배리언트 {#personalized-variant}

캠페인 설정 시 최적화를 위해 **개인화된 배리언트를** 선택한 경우, **A/B 테스트 결과는** 두 개의 탭으로 나뉩니다: **초기 테스트** 및 **개인화된 배리언트**.

{% tabs local %}
{% tab Initial Test %}

**초기 테스트** 탭에는 타겟 세그먼트의 일부로 전송된 초기 A/B 테스트의 각 배리언트에 대한 측정기준이 표시됩니다.

각 사용자에게 가장 적합한 성능/성과의 배리언트를 결정하기 위해 전송된 초기 테스트 결과입니다. 표는 타겟 채널에 대한 다양한 측정기준에 따른 각 배리언트의 성능/성과를 보여줍니다.]({% image_buster /assets/img_archive/ab_analytics_pv_initial_test_1.png %})

기본적으로 테스트는 사용자의 커스텀 이벤트와 메시지 배리언트 기본 설정 간의 연관성을 찾습니다. 이 분석은 커스텀 이벤트가 특정 메시지 배리언트에 대한 응답 가능성을 높이거나 낮추는지를 감지합니다. 그런 다음 이러한 관계를 사용하여 최종 전송에서 어떤 사용자가 어떤 메시지 배리언트를 받을지 결정합니다.

커스텀 이벤트와 메시지 기본 설정 간의 관계는 **초기 보내기** 탭의 표에 표시되어 있습니다.

\![]({% image_buster /assets/img_archive/ab_analytics_pv_3.png %})

테스트에서 커스텀 이벤트와 배리언트 기본 설정 간에 의미 있는 관계를 찾을 수 없는 경우 테스트는 세션 기반 분석 방법으로 돌아갑니다.

{% details Fallback analysis method %}

**세션 기반 분석 방법**<br>
대체 방법을 사용하여 개인화된 배리언트를 결정하는 경우 **초기 테스트** 탭에 특정 특성의 조합에 따라 사용자가 선호하는 배리언트의 분석 결과가 표시됩니다. 

이러한 특성은 다음과 같습니다:

- **최근:** 마지막으로 세션을 진행한 시기
- **빈도:** 세션이 있는 빈도
- **테뉴어:** 사용자로 활동한 기간

예를 들어, 테스트 결과 대부분의 사용자가 배리언트 A를 선호하지만 약 3~12일 전에 세션을 가졌고, 세션 간격이 1~12일이며, 최근 67~577일 사이에 생성된 사용자는 배리언트 B를 선호하는 경향이 있다는 것을 알 수 있습니다. 따라서 해당 하위집단에 속한 사용자는 두 번째 전송에서 배리언트 B를 수신하고 나머지는 배리언트 A를 수신합니다.

최근성, 빈도, 재직 기간에 따라 세 가지 버킷에 속하는 사용자가 배리언트 A와 배리언트 B를 선호할 것으로 예측되는 사용자 특성 표를 확인할 수 있습니다.]({% image_buster /assets/img_archive/ab_analytics_pv_initial_test_2.png %})

**개인화된 배리언트 선택 방법**<br>
이 방법을 사용하면 개별 사용자의 추천 메시지는 특정 사용자의 최근성, 빈도 및 사용 기간에 따른 효과의 합으로 결정됩니다. **사용자 특성** 표에 표시된 것처럼 최근성, 빈도 및 재직 기간은 버킷으로 나뉩니다. 각 버킷의 시간 범위는 각 개별 캠페인의 사용자 데이터에 따라 결정되며 캠페인마다 변경됩니다. 

각 버킷은 각 메시지 배리언트에 대해 서로 다른 기여도 또는 "푸시"를 가질 수 있습니다. 각 버킷에 대한 푸시 강도는 [로지스틱 회귀를](https://en.wikipedia.org/wiki/Logistic_regression) 사용하여 초기 전송의 사용자 응답에서 결정됩니다. 이 표는 각 버킷의 사용자가 어떤 배리언트에 참여하는 경향이 있는지를 표시하여 결과를 요약한 것입니다. 개별 사용자의 실제 개인화된 배리언트는 각 특성에 대해 하나씩 있는 세 개의 버킷 효과의 합에 따라 달라집니다.

{% enddetails %}

{% endtab %}
{% tab Personalized Variant %}

**개인화된 배리언트** 탭에는 남은 각 사용자에게 참여 가능성이 가장 높은 배리언트가 전송된 두 번째 전송의 결과가 표시됩니다.

이 페이지의 세 장의 카드는 예상 상승률, 전체 결과, 그리고 우승 배리언트만 보냈을 때의 예상 결과를 보여줍니다. 간혹 발생할 수 있는 리프트가 없더라도 결과는 기존 A/B 테스트에서 우승한 배리언트만 전송하는 것과 동일합니다. 

- **예상 리프트:** 표준 A/B 테스트 대신 개인화된 배리언트를 사용했기 때문에 이 전송에 대해 선택한 최적화 측정기준이 개선되었습니다(나머지 사용자가 우승 배리언트만 수신한 경우).
- **전체 결과:** 선택한 최적화 측정기준*(고유 열람* 수, *고유 클릭* 수 또는 *주요 전환 이벤트*)에 따른 두 번째 전송 결과입니다.
- **예상 결과:** 위닝 배리언트만 전송했을 경우 선택한 최적화 측정기준에 따라 두 번째 전송의 예상 결과입니다. 

고유 열람에 최적화된 캠페인을 위한 [개인화된 배리언트 탭. 카드에는 예상 상승률, 전체 고유 열람(개인화된 배리언트 포함), 예상 고유 열람(우승 배리언트 포함)이 표시됩니다.]({% image_buster /assets/img_archive/ab_analytics_pv_1.png %})

이 페이지의 표에는 개인화된 배리언트 전송의 각 배리언트에 대한 측정기준이 나와 있습니다. **오디언스 %는** 개인화된 배리언트 그룹에 예약한 타겟 세그먼트의 비율을 합산한 값입니다.

\![]({% image_buster /assets/img_archive/ab_analytics_pv_2.png %})

{% endtab %}
{% endtabs %}

## 자신감 이해 {#understanding-confidence}

신뢰도는 전환율과 같은 데이터의 차이가 우연에 의한 것이 아니라 실제적인 것이라고 얼마나 확신하는지를 나타내는 통계적 척도입니다.

{% alert note %}
결과에 대한 확신이 없으신가요? 신뢰도는 대조군이 있는 경우에만 표시됩니다.
{% endalert %}

결과에서 중요한 부분은 결과의 신뢰도입니다. 예를 들어 대조군의 전환율이 20%이고 배리언트 A의 전환율이 25%였다면 어떻게 될까요? 이는 배리언트 A를 보내는 것이 메시지를 보내지 않는 것보다 더 효과적이라는 것을 나타냅니다. 신뢰도가 95%라는 것은 두 전환율의 차이가 실제 사용자 응답의 차이로 인한 것일 가능성이 높으며, 그 차이가 우연히 발생했을 가능성은 5%에 불과하다는 의미입니다.

Braze는 [Z 테스트라는](https://en.wikipedia.org/wiki/Z-test) 통계 절차를 통해 각 배리언트의 전환율을 대조군의 전환율과 비교합니다. 앞의 예에서와 같이 95% 이상의 신뢰도는 차이가 통계적으로 유의미하다는 것을 나타냅니다. 이는 두 메시지 또는 사용자 집단 간의 차이를 설명하는 신뢰도 측정기준이 Braze 대시보드에 표시되는 모든 곳에 해당됩니다.

일반적으로 결과가 우연이 아닌 사용자의 실제 선호도를 반영한다는 것을 보여주려면 최소 95%의 신뢰도가 필요합니다. 엄격한 과학 테스트에서 통계적 유의성을 판단하는 데 사용되는 일반적인 기준은 95% 신뢰도(또는 일반적으로 'p' 값이 0.05 미만이라고도 함)입니다. 계속해서 95% 신뢰도에 도달하지 못하면 샘플 크기를 늘리거나 배리언트 수를 줄여 보세요. 

신뢰도는 한 배리언트가 다른 배리언트보다 나은지 여부를 설명하지 않습니다. 이는 순전히 두 가지(또는 그 이상) 전환율이 실제로 서로 얼마나 다른지 얼마나 확신하는지를 측정하는 척도입니다. 이는 표본 크기와 겉으로 드러나는 전환율의 차이에 따른 결과일 뿐입니다. 전체 비율이 높든 낮든 신뢰도 측정의 강도에 영향을 미치지 않습니다. 하나의 배리언트가 다른 배리언트와 매우 다른 전환율을 가지면서도 95% 이상의 신뢰도를 갖지 못할 수 있습니다. 두 배리언트 세트의 전환율/상승률은 비슷하지만 신뢰도가 다를 수도 있습니다.

### 통계적으로 유의미하지 않은 결과

신뢰도가 95%가 되지 않는 테스트라도 중요한 인사이트를 얻을 수 있습니다. 다음은 통계적으로 유의미한 결과가 나오지 않은 테스트에서 배울 수 있는 몇 가지 사항입니다:

- 모든 배리언트가 거의 동일한 효과를 냈을 가능성이 있습니다. 이를 알면 이러한 변경 작업을 수행하는 데 소요되는 시간을 절약할 수 있습니다. 때로는 클릭 유도 문안을 반복하는 것과 같은 기존의 마케팅 전략이 오디언스에게 반드시 효과가 없는 경우도 있습니다.
- 결과가 우연에 의한 것일 수도 있지만, 다음 테스트의 가설을 세우는 데 도움이 될 수 있습니다. 여러 배리언트가 거의 동일한 결과를 보이는 경우 새 배리언트와 함께 몇 가지를 다시 실행하여 더 효과적인 대안을 찾을 수 있는지 확인합니다. 한 배리언트의 성능이 더 좋지만 큰 차이가 나지 않는 경우, 이 배리언트의 차이를 더 과장하여 다른 테스트를 수행할 수 있습니다.
- 계속 테스트하세요! 결과가 미미한 테스트는 특정 질문으로 이어져야 합니다. 배리언트 간에 정말 차이가 없나요? 테스트를 다르게 구성했어야 했나요? 후속 테스트를 실행하여 이러한 질문에 답할 수 있습니다.
- 테스트는 어떤 유형의 메시징이 오디언스에게 가장 많은 반응을 이끌어내는지 알아내는 데 유용하지만, 어떤 메시징의 변경이 미미한 효과만 미치는지 파악하는 것도 중요합니다. 이를 통해 더 효과적인 다른 대안을 계속 테스트하거나 두 가지 대체 메시지 중 하나를 결정하는 데 소요되는 시간을 저장할 수 있습니다.

테스트에 명확한 승자가 있든 없든, [후속 테스트를](#recommended-follow-ups) 실행하여 결과를 확인하거나 약간 다른 시나리오에 결과를 적용하는 것이 도움이 될 수 있습니다.

## 대조군과 배리언트 간의 차이점

인앱 메시지 캠페인에서 사용자를 추적하는 방식과 노출 횟수가 기록되는 방식에 따라 대조군과 배리언트 간의 예상 분할에 차이가 발생할 수 있습니다. 이는 기록된 실제 노출 횟수가 이러한 분할을 반영하지 않을 수 있으며, Braze는 궁극적으로 트리거를 수행할 개별 사용자 행동을 제어할 수 없기 때문입니다.

예를 들어, 캠페인 시작 시 타겟 오디언스가 200명이고 대조군에 100명, 배리언트에 100명의 사용자가 있다고 가정해 보겠습니다.

배리언트에서 100명의 사용자가 인앱 메시지 페이로드를 수신하고, 그 중 50명이 트리거 동작을 수행하여 인앱 메시지를 확인합니다. 대조군의 사용자 100명은 캠페인의 트리거 동작을 수행한 경우에만 추적되며, 그 중 75명은 트리거 동작을 수행하여 노출 횟수는 기록하지만 인앱 메시지는 표시되지 않습니다.

초기 50/50 분할에도 불구하고 기록된 고유 노출 횟수의 균형이 맞지 않습니다. 배리언트 그룹은 노출 횟수가 50회인 반면 대조군은 75회입니다.

### 인앱 메시지 지연 

지연 표시가 포함된 트리거된 인앱 메시지 캠페인의 경우, 최종 사용자가 원래 인앱 메시지를 수신했을 때 대조군 노출 횟수가 기록됩니다. 예를 들어, 캠페인이 1시간 지연 표시되도록 설정된 경우, 1시간 지연이 경과할 때까지 대조군 노출 횟수는 기록되지 않습니다. 이를 통해 의도한 메시지 전달 타이밍과 관련된 노출 횟수를 정확하게 추적할 수 있습니다.

## 권장 후속 조치 {#recommended-follow-ups}

다변량 및 A/B 테스트를 통해 향후 테스트에 대한 아이디어를 얻을 수 있을 뿐만 아니라 메시징 전략의 변화를 유도할 수 있습니다. 가능한 후속 조치는 다음과 같습니다:

#### 테스트 결과에 따라 메시징 전략 변경하기

다변량 결과에 따라 메시징의 문구나 서식을 변경해야 할 수도 있습니다.

#### 사용자를 이해하는 방식을 바꾸세요

각 테스트를 통해 사용자의 행동, 사용자가 다양한 메시징 채널에 반응하는 방식, 세그먼트 간의 차이점(및 유사점)을 파악할 수 있습니다.

#### 향후 테스트 구성 방식 개선

샘플 크기가 너무 작았나요? 배리언트 간의 차이가 너무 미묘하지 않았나요? 각 테스트는 향후 테스트를 개선할 수 있는 방법을 배울 수 있는 기회를 제공합니다. 신뢰도가 낮으면 표본 크기가 너무 작으므로 향후 테스트를 위해 표본 크기를 확대해야 합니다. 배리언트의 성능/성과에 뚜렷한 차이가 없다면 그 차이가 너무 미묘해서 사용자의 반응에 눈에 띄는 영향을 미치지 못했을 가능성이 있습니다.

#### 더 큰 샘플 크기로 후속 테스트 실행하기

샘플이 클수록 배리언트 간의 작은 차이를 감지할 수 있는 가능성이 높아집니다.

#### 다른 메시징 채널을 사용하여 후속 테스트 실행하기

특정 전략이 한 채널에서 매우 효과적이라는 것을 알게 되면 다른 채널에서도 해당 전략을 테스트해 볼 수 있습니다. 한 유형의 메시지가 한 채널에서는 효과적이지만 다른 채널에서는 효과가 없는 경우 특정 채널이 특정 유형의 메시지에 더 도움이 된다는 결론을 내릴 수 있습니다. 또는 푸시 알림을 인에이블먼트할 가능성이 높은 사용자와 인앱 메시지에 주의를 기울일 가능성이 높은 사용자 간에 차이가 있을 수도 있습니다. 궁극적으로 이러한 종류의 테스트를 실행하면 오디언스가 다양한 커뮤니케이션 채널과 상호 작용하는 방식을 파악하는 데 도움이 됩니다.

#### 다른 사용자 세그먼트에 대해 후속 테스트 실행하기

이렇게 하려면 동일한 메시징 채널 및 배리언트로 다른 테스트를 만들되, 다른 사용자 세그먼트를 선택하세요. 예를 들어, 한 가지 유형의 메시징이 참여 사용자에게 매우 효과적이었다면 휴면 사용자에게 미치는 영향을 조사하는 것이 유용할 수 있습니다. 이탈한 사용자도 비슷한 반응을 보이거나 다른 배리언트 중 하나를 더 선호할 수 있습니다. 이 테스트를 통해 다양한 세그먼트와 이들이 다양한 유형의 메시지에 어떻게 반응하는지 자세히 알아볼 수 있습니다. 데이터에 기반하여 전략을 수립할 수 있는데 왜 세그먼트에 대해 추측을 할까요?

#### 이전 테스트에서 얻은 인사이트를 기반으로 후속 테스트 실행

과거 테스트에서 얻은 인사이트를 바탕으로 향후 테스트를 계획하세요. 이전 테스트에서 한 가지 메시징 기법이 더 효과적이라는 힌트를 얻었나요? 배리언트의 어떤 부분이 더 나은지 잘 모르시나요? 이러한 질문을 기반으로 후속 테스트를 실행하면 사용자에 대한 인사이트가 담긴 결과를 도출하는 데 도움이 됩니다.

#### 다양한 배리언트의 장기적인 영향 비교하기

재참여 메시지를 A/B 테스트하는 경우, [리텐션 보고서를]({{site.baseurl}}/user_guide/analytics/reporting/retention_reports/) 사용하여 다양한 배리언트의 장기적인 영향을 비교하는 것을 잊지 마세요. 리텐션 보고서를 사용하여 메시지 수신 후 며칠, 몇 주, 한 달 동안 각 배리언트가 선택한 사용자 행동에 어떤 영향을 미쳤는지 분석하고, 상승세가 있는지 확인할 수 있습니다.
