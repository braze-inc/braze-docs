モデルの精度を測定するために、_予測品質_メトリックは、過去のデータでテストしたときに、この特定の機械学習モデルがどの程度効果的に見えるかを示す。Brazeは、モデル作成ページで指定したグループに従ってデータをプルする。モデルは、1つのデータセット (「トレーニング」セット)でトレーニングされ、次に新しい別のデータセット (「テスト」セット)でテストされる。

予測は2週間ごとに再度トレーニングされ、_Prediction Quality_指標とともに更新されるため、最新のユーザー行動パターンに基づいて予測が更新される。さらに、その都度、直近2週間の予測を実際のユーザーの結果と照らし合わせてテストする。_予測品質は_、 (予測ではなく)これらの実際の結果に基づいて計算される。これは、実際のシナリオで予測が正確であることを確認するための自動バックテスト (つまり、過去のデータを使って予測モデルをテストすること)である。この再トレーニングとバックテストが最後に行われた時間は、**予測**ページと個々の予測の分析ページに表示される。プレビュー予測であっても、作成後に一度だけこのバックテストが実行される。こうすることで、無料版でもカスタマイズされた予測の精度を確かめることができる。

{% details Prediction quality example %}

例えば、通常、ユーザーの平均 20% が解約する場合、ユーザーの 20% のサブセットを無作為に選択し、それらのユーザーに「解約済み」のラベルを無作為に付けると (実際に解約したかどうかは問わない)、正しく特定される解約者は実際の 20% のみであると予想されます。それは当て推量です。もし、このモデルがその程度しかできないとしたら、この場合の揚力は1となる。

一方、モデルがユーザーの 20% にメッセージを送信することを許可し、その結果、「真の」解約者をすべて捕捉し、解約者以外をまったく捕捉しなかった場合、リフトは 100% / 20% = 5 になります。この比率を、メッセージを送信できる、解約の可能性が非常に高いユーザーの割合ごとにグラフにすると、[リフト曲線](https://en.wikipedia.org/wiki/Lift_(data_mining))が得られます。 

リフト品質 (および_予測品質_) を検討するもう 1 つの方法は、テストセットで解約者を特定する予測のリフト曲線が当て推量 (0%) から完全 (100%) までのどの位置にあるかです。リフト品質に関する元の論文については、「[Measuring lift quality in database marketing](https://dl.acm.org/doi/10.1145/380995.381018)」を参照してください。

{% enddetails %}

### 測定方法

当社の_予測品質_の尺度は[リフト品質](https://dl.acm.org/doi/10.1145/380995.381018)です。一般に、"lift"は、コンバージョンなどの成功した結果の割合またはパーセンテージeの増加を意味します。ここでの成功した結果とは、解約したであろうユーザーを正しく特定することです。リフト品質とは、テストセットにメッセージングを行うときに考えられるすべてのオーディエンスサイズについて、予測が提供する平均リフトです。このアプローチでは、モデルがランダムな推測よりもどれだけ優れているかを測定する。この指標の 0% は、誰が解約するかについて、モデルの精度がランダムな推測と同程度であり、100% は誰が解約するかを完全に把握していることを示します。

### 推奨範囲

以下に、さまざまな_予測品質_範囲に対する推奨事項を示します。

| 予測品質範囲(%) | 推奨 |
| ---------------------- | -------------- |
| 60 - 100 | 非常に良い。トップクラスの精度。オーディエンスの定義を変更しても新たなメリットが得られる可能性はあまりありません。 |
| 40 - 60 | 良い。このモデルでは正確な予測が生成されますが、さまざまなオーディエンス設定を試すことで、さらに正確な結果が得られる可能性があります。 |
| 20 - 40| 普通。このモデルでは正確で価値のある予測が提供されますが、さまざまなオーディエンス定義を試して、パフォーマンスが向上するかどうかを確認してみてください。 |
| 0 - 20 | 悪い。オーディエンスの定義を変更して、もう一度やり直すことをお勧めします。 |
{: .reset-td-br-1 .reset-td-br-2 role="presentation" }
